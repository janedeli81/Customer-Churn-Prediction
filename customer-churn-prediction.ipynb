{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83793,"databundleVersionId":9336896,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\nfrom imblearn.over_sampling import SMOTE\nimport optuna\n\n# Load data\ntrain_data = pd.read_csv('/kaggle/input/ml-fundamentals-and-applications-2024-08/final_proj_data.csv')\ntest_data = pd.read_csv('/kaggle/input/ml-fundamentals-and-applications-2024-08/final_proj_test.csv')\nsample_submission = pd.read_csv('/kaggle/input/ml-fundamentals-and-applications-2024-08/final_proj_sample_submission.csv')\n\n# Identify numerical and categorical features\nnumeric_features = train_data.select_dtypes(include=['number']).columns.drop('y', errors='ignore')\ncategorical_features = train_data.select_dtypes(include=['object']).columns\n\n# Remove numeric features with all missing values\nnumeric_features = [col for col in numeric_features if train_data[col].notna().any()]\n\n# Define pipelines for numerical and categorical preprocessing\nnumeric_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine transformers into a ColumnTransformer\npreprocessor = ColumnTransformer([\n    ('num', numeric_transformer, numeric_features),\n    ('cat', categorical_transformer, categorical_features)\n])\n\n# Separate features and target variable\nX = train_data.drop(columns=['y'])\ny = train_data['y']\n\n# Preprocess data\nX_preprocessed = preprocessor.fit_transform(X)\n\n# Split into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42, stratify=y)\n\n# Apply SMOTE for class balancing\nsmote = SMOTE(random_state=42)\nX_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n# Hyperparameter tuning function\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'random_state': 42\n    }\n    print(f\"Trying parameters: {params}\")\n    model = GradientBoostingClassifier(**params)\n    model.fit(X_train_res, y_train_res)\n    y_pred = model.predict(X_val)\n    score = f1_score(y_val, y_pred, average='binary')\n    print(f\"Trial completed with F1 Score: {score:.4f}\")\n    return score\n\n# Run Optuna optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)\n\n# Best parameters\nbest_params = study.best_params\nprint(\"Best hyperparameters:\", best_params)\n\n# Train final model with best parameters\nmodel = GradientBoostingClassifier(**best_params, random_state=42)\nmodel.fit(X_train_res, y_train_res)\n\n# Function to evaluate model performance\ndef evaluate_model(y_true, y_pred):\n    print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_true, y_pred):.4f}\")\n    print(f\"Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}\")\n    print(f\"F1 Score: {f1_score(y_true, y_pred, average='binary'):.4f}\")\n    print(f\"Precision: {precision_score(y_true, y_pred, average='binary'):.4f}\")\n    print(f\"Recall: {recall_score(y_true, y_pred, average='binary'):.4f}\")\n\n# Validate the model\ny_pred = model.predict(X_val)\nevaluate_model(y_val, y_pred)\n\n# Preprocess test data\nX_test_preprocessed = preprocessor.transform(test_data)\n\n# Make predictions on test set\ntest_predictions = model.predict(X_test_preprocessed)\n\n# Create submission file\nsubmission = pd.DataFrame({\n    'index': sample_submission['index'], \n    'y': test_predictions\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T13:49:51.166651Z","iopub.execute_input":"2025-03-20T13:49:51.167180Z","iopub.status.idle":"2025-03-20T16:06:52.078128Z","shell.execute_reply.started":"2025-03-20T13:49:51.167143Z","shell.execute_reply":"2025-03-20T16:06:52.077115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}